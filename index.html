<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pure JavaScript Proxy Scraper</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap');
        body { font-family: 'Inter', sans-serif; background-color: #f7f9fb; }
        .container { max-width: 900px; }
        /* Style for copy button on hover */
        .copy-link:hover .copy-icon { opacity: 1; }
    </style>
</head>
<body class="min-h-screen p-4 sm:p-8 flex justify-center">

    <div class="container w-full">
        <!-- Header -->
        <header class="text-center mb-10">
            <h1 class="text-4xl font-extrabold text-teal-600">Pure JavaScript Link Scraper</h1>
            <p class="text-gray-500 mt-2">Fetches and extracts all links (`<a>` tags) from a given URL.</p>
            <p class="text-sm text-amber-600 mt-1 font-semibold">
                NOTE: This uses a public proxy service (api.allorigins.win) to bypass browser security restrictions (CORS).
            </p>
        </header>

        <!-- Input and Control Panel -->
        <div class="bg-white p-6 sm:p-8 rounded-xl shadow-2xl transition-all duration-300">
            <div class="flex flex-col md:flex-row gap-4">
                <input type="url" id="urlInput" placeholder="Enter a full URL (e.g., https://www.google.com)"
                       class="flex-grow p-3 border-2 border-gray-200 rounded-lg focus:border-teal-500 focus:ring-1 focus:ring-teal-500 text-gray-700 transition duration-150"
                       value="https://www.ticketmaster.com.au">
                
                <button id="scrapeButton"
                        class="bg-teal-600 hover:bg-teal-700 text-white font-semibold py-3 px-6 rounded-lg shadow-md transition duration-150 ease-in-out transform hover:scale-[1.02] active:scale-[0.98] disabled:bg-teal-300 flex items-center justify-center">
                    Scrape Links
                </button>
            </div>
        </div>

        <!-- Results Display Area -->
        <div class="mt-8 bg-white p-6 sm:p-8 rounded-xl shadow-2xl">
            <h2 class="text-2xl font-bold text-gray-800 mb-4">
                Results <span id="linkCount" class="text-teal-600">(0 links found)</span>
            </h2>
            <div id="resultsContainer" class="max-h-96 overflow-y-auto border border-gray-200 rounded-lg p-3 bg-gray-50">
                <p id="initialMessage" class="text-gray-400 italic">Enter a URL and click "Scrape Links" to begin.</p>
                <ul id="linkList" class="space-y-2 hidden">
                    <!-- Links will be injected here -->
                </ul>
            </div>
            
            <!-- Download Button -->
            <button id="downloadButton"
                    class="mt-4 w-full bg-blue-500 hover:bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg shadow-md transition duration-150 ease-in-out transform hover:scale-[1.01] active:scale-[0.99] disabled:bg-blue-300 hidden"
                    disabled>
                Download Results as CSV
            </button>
        </div>
    </div>

    <script>
        // --- Configuration ---
        const PROXY_URL = 'https://api.allorigins.win/get?url=';

        // --- DOM Elements ---
        const urlInput = document.getElementById('urlInput');
        const scrapeButton = document.getElementById('scrapeButton');
        const downloadButton = document.getElementById('downloadButton');
        const resultsContainer = document.getElementById('resultsContainer');
        const linkList = document.getElementById('linkList');
        const linkCountSpan = document.getElementById('linkCount');
        const initialMessage = document.getElementById('initialMessage');

        // --- State Management ---
        let lastScrapedLinks = [];

        // --- Event Listeners ---
        scrapeButton.addEventListener('click', handleScrape);
        downloadButton.addEventListener('click', downloadCSV);

        // --- Scraper Core Logic ---
        
        function setAppState(isLoading) {
            scrapeButton.disabled = isLoading;
            downloadButton.disabled = isLoading;
            
            if (isLoading) {
                scrapeButton.innerHTML = `
                    <svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg> 
                    Scraping...`;
                initialMessage.classList.add('hidden');
                linkList.classList.add('hidden');
                linkList.innerHTML = '';
                linkCountSpan.textContent = '(Loading...)';
                downloadButton.classList.add('hidden');
                displayMessage("Fetching content via proxy...", 'info');
            } else {
                scrapeButton.innerHTML = 'Scrape Links';
            }
        }

        async function handleScrape() {
            let url = urlInput.value.trim();
            if (!url) { displayNotification("Please enter a valid URL.", 'error'); return; }

            // Ensure protocol is included for the proxy to work correctly
            if (!url.startsWith('http')) {
                url = 'https://' + url;
                urlInput.value = url;
            }

            setAppState(true);
            lastScrapedLinks = []; // Clear previous results

            try {
                // 1. Fetch data through the public proxy service
                const proxyUrl = `${PROXY_URL}${encodeURIComponent(url)}`;
                
                const response = await fetch(proxyUrl);
                const proxyData = await response.json();
                
                if (!response.ok || proxyData.status && proxyData.status.http_code >= 400) {
                     displayNotification(`Proxy Error: Could not fetch URL (${proxyData.status?.http_code || response.status}).`, 'error');
                     return;
                }
                
                // The actual HTML content is inside proxyData.contents
                const htmlContent = proxyData.contents;
                
                // 2. Use DOMParser to process the received HTML string
                const parser = new DOMParser();
                const doc = parser.parseFromString(htmlContent, 'text/html');

                // 3. Find all <a> tags
                const allATags = doc.querySelectorAll('a');
                
                let foundLinks = [];

                allATags.forEach(aTag => {
                    const href = aTag.getAttribute('href');
                    const text = aTag.textContent.trim();

                    if (href) {
                        foundLinks.push({
                            text: text,
                            url: href
                        });
                    }
                });

                // 4. Success: Display the links
                lastScrapedLinks = foundLinks;
                displayLinks(lastScrapedLinks);
                
            } catch (error) {
                console.error("Scraping/Processing Error:", error);
                displayNotification(`An unexpected error occurred during processing: ${error.message}`, 'error');
            }
            
            setAppState(false);
        }
        
        // --- Display and Utility Functions ---

        function displayLinks(links) {
            linkList.innerHTML = '';
            linkCountSpan.textContent = `(${links.length} links found)`;
            resultsContainer.innerHTML = ''; // Clear status message
            
            if (links.length === 0) {
                displayNotification("No links (`<a>` tags) were found on the page.", 'info');
                downloadButton.classList.add('hidden');
                return;
            }

            links.forEach(link => {
                const li = document.createElement('li');
                li.className = 'p-3 bg-white border border-gray-100 rounded-md shadow-sm hover:shadow-md transition duration-150 break-words';
                
                const textDiv = document.createElement('div');
                textDiv.className = 'font-semibold text-gray-800';
                textDiv.textContent = link.text || '[No Link Text]';

                const urlDiv = document.createElement('a');
                urlDiv.className = 'text-sm text-teal-500 hover:underline';
                urlDiv.href = link.url;
                urlDiv.target = '_blank';
                urlDiv.textContent = link.url;

                li.appendChild(textDiv);
                li.appendChild(urlDiv);
                linkList.appendChild(li);
            });

            linkList.classList.remove('hidden');
            resultsContainer.appendChild(linkList); // Put the list back in the container
            downloadButton.classList.remove('hidden');
            downloadButton.disabled = false;
        }

        function displayNotification(message, type) {
            resultsContainer.innerHTML = ''; // Clear previous content
            const p = document.createElement('p');
            p.textContent = message;
            p.className = `p-4 rounded-lg font-medium ${type === 'error' ? 'bg-red-100 text-red-700' : 'bg-blue-100 text-blue-700'}`;
            resultsContainer.appendChild(p);
            downloadButton.classList.add('hidden');
        }

        function downloadCSV() {
            if (lastScrapedLinks.length === 0) { displayNotification("No data available to download.", 'error'); return; }

            let csvContent = "Link Text,URL\n";

            lastScrapedLinks.forEach(link => {
                // Sanitize text for CSV: replace double quotes with single quotes, and wrap in double quotes
                const sanitizedText = `"${(link.text || '').replace(/"/g, "'")}"`;
                const url = link.url || '';
                
                csvContent += `${sanitizedText},${url}\n`;
            });

            const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'scraped_links.csv';
            
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }

    </script>
</body>
</html>